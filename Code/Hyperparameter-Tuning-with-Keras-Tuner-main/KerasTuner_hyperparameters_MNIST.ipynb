{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDFc-NhsqlyF",
        "outputId": "e1bfe838-d963-43b2-daf6-f950449a7d18"
      },
      "outputs": [],
      "source": [
        "# #installing keras-tuner\n",
        "# !pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z1PyxJSotiPJ"
      },
      "outputs": [],
      "source": [
        "#importing necessary liabraries\n",
        "import tensorflow as tf\n",
        "import keras_tuner\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "x7fdazbQt5q-"
      },
      "outputs": [],
      "source": [
        "#loading dataset and spliting it in test and train dataset\n",
        "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n6pR8iGuJHy",
        "outputId": "9fb2a6e2-9947-48d5-a340-8b349bad752b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#check x_train shape\n",
        "x_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKpAKb7vuViF",
        "outputId": "c8136879-b53a-4414-aa9b-dccb5f622c64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#setting the y_train data\n",
        "set(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "IkqV1fJ7ucds",
        "outputId": "83ebcf1d-45eb-4ee9-f016-d7e9d408c622"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#checking a random element 7 and visualizing it\n",
        "plt.imshow(x_train[7],cmap='binary')\n",
        "plt.xlabel(y_train[7])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "92j1yCXZvIeB"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, Flatten, Dense, Dropout, Concatenate\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "def residual_block(input_tensor, filters):\n",
        "    x = Conv2D(filters, kernel_size=(5, 5), activation='relu', padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(filters, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Add()([x, input_tensor])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def create_model(hp=None):\n",
        "    filters = 64\n",
        "    dropout_rate = 0.25\n",
        "    dense_units_1 = 256\n",
        "    dense_units_2 = 128\n",
        "    learning_rate = 0.001\n",
        "\n",
        "    if hp:\n",
        "        filters = hp.Choice('filters', values=[32, 64, 128])\n",
        "        dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5)\n",
        "        dense_units_1 = hp.Choice('dense_units_1', values=[128, 256, 512])\n",
        "        dense_units_2 = hp.Choice('dense_units_2', values=[64, 128, 256])\n",
        "        learning_rate = hp.Float('learning_rate', min_value=0.0001, max_value=0.01)\n",
        "\n",
        "    input_shape = (28, 28, 1)\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # First backbone\n",
        "    x1 = Conv2D(filters, kernel_size=(3, 3), activation='relu')(inputs)\n",
        "    x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
        "    x1 = Dropout(dropout_rate)(x1)\n",
        "    x1 = residual_block(x1, filters=filters)\n",
        "    x1 = Dropout(dropout_rate)(x1)\n",
        "\n",
        "    # Second backbone\n",
        "    x2 = Conv2D(filters, kernel_size=(3, 3), activation='relu')(inputs)\n",
        "    x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
        "    x2 = Dropout(dropout_rate)(x2)\n",
        "    x2 = residual_block(x2, filters=filters)\n",
        "    x2 = Dropout(dropout_rate)(x2)\n",
        "\n",
        "    # Concatenate the two backbones\n",
        "    x = Concatenate()([x1, x2])\n",
        "    \n",
        "    x = Conv2D(filters, kernel_size=(3, 3), activation='relu')(inputs)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = residual_block(x, filters=filters)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(dense_units_1, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Dense(dense_units_2, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmqkiHNhxHCE",
        "outputId": "5f10fb30-db27-41ab-ed99-dd332b5ed087"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">102,464</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10816</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,769,152</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │ batch_normalizat… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m,    │        \u001b[38;5;34m640\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │    \u001b[38;5;34m102,464\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ activation_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10816\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │  \u001b[38;5;34m2,769,152\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ batch_normalizat… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │      \u001b[38;5;34m1,290\u001b[0m │ batch_normalizat… │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,945,418</span> (11.24 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,945,418\u001b[0m (11.24 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,944,394</span> (11.23 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,944,394\u001b[0m (11.23 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#creating model summary\n",
        "create_model(None).summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "e1Uc8O9cxPVn"
      },
      "outputs": [],
      "source": [
        "#defining a class with custom tuner using bayesian optimzation\n",
        "class CustomTuner(keras_tuner.tuners.BayesianOptimization):\n",
        "  def run_trial(self,trial, *args, **kwargs):\n",
        "    kwargs['batch_size']=trial.hyperparameters.Int('batch_size',32,128,step=32) #giving batch size\n",
        "    super(CustomTuner,self).run_trial(trial,*args,**kwargs)\n",
        "    model = self.hypermodel.build(trial.hyperparameters)\n",
        "    history = model.fit(x_train, y_train, validation_split=0.2, epochs=10)\n",
        "    return history.history['val_accuracy'][-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JoKJoqgfzmSJ"
      },
      "outputs": [],
      "source": [
        "#running a custom tuner\n",
        "tuner=CustomTuner(\n",
        "    create_model,\n",
        "    objective='val_accuracy', #validation accuracy\n",
        "    max_trials=20,           #defining max number of trials\n",
        "    directory='logs',\n",
        "    project_name='fashion_mnist',\n",
        "    overwrite=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLgcDaIW0dUM",
        "outputId": "f5964e47-3701-45d3-8fc7-6f5807d16a8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 5\n",
            "filters (Choice)\n",
            "{'default': 32, 'conditions': [], 'values': [32, 64, 128], 'ordered': True}\n",
            "dropout_rate (Float)\n",
            "{'default': 0.1, 'conditions': [], 'min_value': 0.1, 'max_value': 0.5, 'step': None, 'sampling': 'linear'}\n",
            "dense_units_1 (Choice)\n",
            "{'default': 128, 'conditions': [], 'values': [128, 256, 512], 'ordered': True}\n",
            "dense_units_2 (Choice)\n",
            "{'default': 64, 'conditions': [], 'values': [64, 128, 256], 'ordered': True}\n",
            "learning_rate (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'linear'}\n"
          ]
        }
      ],
      "source": [
        "tuner.search_space_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kvMWIjtq7B0q"
      },
      "outputs": [],
      "source": [
        "# tuner.search(\n",
        "#     x_train,y_train,\n",
        "#     validation_data=(x_test,y_test),\n",
        "#     epochs=5,verbose=False\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJ9BgDs54efe",
        "outputId": "59d3357c-cc58-4dbc-a9cf-92f89e216c96"
      },
      "outputs": [],
      "source": [
        "# tuner.results_summary(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faSkpD1e4vSm",
        "outputId": "67be5865-fa9c-40b7-f32a-b5a987ee23de"
      },
      "outputs": [],
      "source": [
        "# model=tuner.get_best_models(num_models=1)[0]\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QidZ6ZUi5BAM",
        "outputId": "393511eb-ee40-48b0-bc5f-844e0646f3af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 87ms/step - accuracy: 0.8037 - loss: 0.5711 - val_accuracy: 0.8714 - val_loss: 0.3370 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 89ms/step - accuracy: 0.8991 - loss: 0.2777 - val_accuracy: 0.9032 - val_loss: 0.2657 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.9153 - loss: 0.2319 - val_accuracy: 0.9094 - val_loss: 0.2440 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 92ms/step - accuracy: 0.9214 - loss: 0.2103 - val_accuracy: 0.9126 - val_loss: 0.2405 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.9295 - loss: 0.1883 - val_accuracy: 0.8992 - val_loss: 0.2757 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.9356 - loss: 0.1723 - val_accuracy: 0.8955 - val_loss: 0.2872 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 96ms/step - accuracy: 0.9406 - loss: 0.1597 - val_accuracy: 0.9226 - val_loss: 0.2253 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 93ms/step - accuracy: 0.9462 - loss: 0.1439 - val_accuracy: 0.9194 - val_loss: 0.2389 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 93ms/step - accuracy: 0.9473 - loss: 0.1363 - val_accuracy: 0.9150 - val_loss: 0.2407 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.9529 - loss: 0.1240 - val_accuracy: 0.9261 - val_loss: 0.2305 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.9573 - loss: 0.1151 - val_accuracy: 0.9190 - val_loss: 0.2386 - learning_rate: 0.0010\n",
            "Epoch 12/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.9556 - loss: 0.1164 - val_accuracy: 0.9224 - val_loss: 0.2592 - learning_rate: 0.0010\n",
            "Epoch 13/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.9665 - loss: 0.0873 - val_accuracy: 0.9316 - val_loss: 0.2263 - learning_rate: 2.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.9724 - loss: 0.0729 - val_accuracy: 0.9291 - val_loss: 0.2325 - learning_rate: 2.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.9751 - loss: 0.0677 - val_accuracy: 0.9321 - val_loss: 0.2338 - learning_rate: 2.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.9776 - loss: 0.0598 - val_accuracy: 0.9323 - val_loss: 0.2450 - learning_rate: 2.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.9790 - loss: 0.0567 - val_accuracy: 0.9315 - val_loss: 0.2434 - learning_rate: 2.0000e-04\n",
            "Epoch 17: early stopping\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train_2 = to_categorical(y_train, num_classes=10)\n",
        "y_test_2 = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "model = create_model()\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=10, monitor='val_loss', mode='min', verbose=1)\n",
        "\n",
        "fit = model.fit(\n",
        "    x_train,y_train_2,\n",
        "    validation_data=(x_test,y_test_2),\n",
        "    epochs=20,batch_size=128,\n",
        "    callbacks=[early_stopping_monitor, reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9293 - loss: 0.2523\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.2434195727109909, 0.9315000176429749]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(x_test, y_test_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "def residual_block_1(input_tensor, filters):\n",
        "    x = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(input_tensor)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(filters, kernel_size=(3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Add()([x, input_tensor])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def create_model_1(hp=None):\n",
        "    filters = 64\n",
        "    dropout_rate = 0.25\n",
        "    dense_units_1 = 256\n",
        "    dense_units_2 = 128\n",
        "    learning_rate = 0.001\n",
        "\n",
        "    if hp:\n",
        "        filters = hp.Choice('filters', values=[32, 64, 128])\n",
        "        dropout_rate = hp.Float('dropout_rate', min_value=0.1, max_value=0.5)\n",
        "        dense_units_1 = hp.Choice('dense_units_1', values=[128, 256, 512])\n",
        "        dense_units_2 = hp.Choice('dense_units_2', values=[64, 128, 256])\n",
        "        learning_rate = hp.Float('learning_rate', min_value=0.0001, max_value=0.01)\n",
        "\n",
        "    input_shape = (28, 28, 1)\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(filters, kernel_size=(3, 3), activation='relu')(inputs)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = residual_block(x, filters=filters)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    x = residual_block(x, filters=filters)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    x = Dense(dense_units_1, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = Dense(dense_units_2, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    outputs = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 140ms/step - accuracy: 0.7488 - loss: 0.7236 - val_accuracy: 0.8845 - val_loss: 0.3163 - learning_rate: 0.0010\n",
            "Epoch 2/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 137ms/step - accuracy: 0.8823 - loss: 0.3301 - val_accuracy: 0.9025 - val_loss: 0.2690 - learning_rate: 0.0010\n",
            "Epoch 3/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 137ms/step - accuracy: 0.8997 - loss: 0.2750 - val_accuracy: 0.9063 - val_loss: 0.2581 - learning_rate: 0.0010\n",
            "Epoch 4/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 137ms/step - accuracy: 0.9082 - loss: 0.2480 - val_accuracy: 0.9022 - val_loss: 0.2626 - learning_rate: 0.0010\n",
            "Epoch 5/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 140ms/step - accuracy: 0.9151 - loss: 0.2298 - val_accuracy: 0.9103 - val_loss: 0.2381 - learning_rate: 0.0010\n",
            "Epoch 6/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 137ms/step - accuracy: 0.9198 - loss: 0.2165 - val_accuracy: 0.8872 - val_loss: 0.2951 - learning_rate: 0.0010\n",
            "Epoch 7/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 139ms/step - accuracy: 0.9111 - loss: 0.2420 - val_accuracy: 0.9007 - val_loss: 0.2660 - learning_rate: 0.0010\n",
            "Epoch 8/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 140ms/step - accuracy: 0.9185 - loss: 0.2187 - val_accuracy: 0.9029 - val_loss: 0.2638 - learning_rate: 0.0010\n",
            "Epoch 9/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 139ms/step - accuracy: 0.9237 - loss: 0.2031 - val_accuracy: 0.9103 - val_loss: 0.2494 - learning_rate: 0.0010\n",
            "Epoch 10/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 138ms/step - accuracy: 0.9312 - loss: 0.1834 - val_accuracy: 0.9110 - val_loss: 0.2462 - learning_rate: 0.0010\n",
            "Epoch 11/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 139ms/step - accuracy: 0.9399 - loss: 0.1617 - val_accuracy: 0.9273 - val_loss: 0.2023 - learning_rate: 2.0000e-04\n",
            "Epoch 12/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 140ms/step - accuracy: 0.9460 - loss: 0.1479 - val_accuracy: 0.9274 - val_loss: 0.2022 - learning_rate: 2.0000e-04\n",
            "Epoch 13/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 141ms/step - accuracy: 0.9474 - loss: 0.1434 - val_accuracy: 0.9238 - val_loss: 0.2115 - learning_rate: 2.0000e-04\n",
            "Epoch 14/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 144ms/step - accuracy: 0.9469 - loss: 0.1409 - val_accuracy: 0.9283 - val_loss: 0.2033 - learning_rate: 2.0000e-04\n",
            "Epoch 15/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 138ms/step - accuracy: 0.9487 - loss: 0.1367 - val_accuracy: 0.9293 - val_loss: 0.2038 - learning_rate: 2.0000e-04\n",
            "Epoch 16/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 136ms/step - accuracy: 0.9525 - loss: 0.1256 - val_accuracy: 0.9309 - val_loss: 0.1997 - learning_rate: 2.0000e-04\n",
            "Epoch 17/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 142ms/step - accuracy: 0.9524 - loss: 0.1292 - val_accuracy: 0.9308 - val_loss: 0.2013 - learning_rate: 2.0000e-04\n",
            "Epoch 18/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 134ms/step - accuracy: 0.9519 - loss: 0.1277 - val_accuracy: 0.9282 - val_loss: 0.2157 - learning_rate: 2.0000e-04\n",
            "Epoch 19/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 139ms/step - accuracy: 0.9552 - loss: 0.1199 - val_accuracy: 0.9309 - val_loss: 0.2066 - learning_rate: 2.0000e-04\n",
            "Epoch 20/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 139ms/step - accuracy: 0.9573 - loss: 0.1170 - val_accuracy: 0.9327 - val_loss: 0.2017 - learning_rate: 2.0000e-04\n",
            "Epoch 21/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 141ms/step - accuracy: 0.9571 - loss: 0.1127 - val_accuracy: 0.9313 - val_loss: 0.2006 - learning_rate: 2.0000e-04\n",
            "Epoch 22/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 137ms/step - accuracy: 0.9581 - loss: 0.1119 - val_accuracy: 0.9342 - val_loss: 0.1997 - learning_rate: 1.0000e-04\n",
            "Epoch 23/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 138ms/step - accuracy: 0.9603 - loss: 0.1059 - val_accuracy: 0.9330 - val_loss: 0.2030 - learning_rate: 1.0000e-04\n",
            "Epoch 24/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 136ms/step - accuracy: 0.9627 - loss: 0.1022 - val_accuracy: 0.9340 - val_loss: 0.2042 - learning_rate: 1.0000e-04\n",
            "Epoch 25/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 138ms/step - accuracy: 0.9621 - loss: 0.1008 - val_accuracy: 0.9323 - val_loss: 0.2068 - learning_rate: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.utils import to_categorical\n",
        "model_1 = create_model_1()\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "early_stopping_monitor = EarlyStopping(patience=10, monitor='val_loss', mode='min', verbose=1)\n",
        "\n",
        "y_train_1 = to_categorical(y_train, num_classes=10)\n",
        "y_test_1 = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "fit = model_1.fit(\n",
        "    x_train, y_train_1,\n",
        "    validation_data=(x_test, y_test_1),\n",
        "    epochs=25, batch_size=128,\n",
        "    callbacks=[early_stopping_monitor, reduce_lr]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9296 - loss: 0.2175\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.20678886771202087, 0.9322999715805054]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1.evaluate(x_test, y_test_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 147ms/step - accuracy: 0.9740 - loss: 0.0000e+00 - val_accuracy: 0.9199 - val_loss: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 2/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 149ms/step - accuracy: 0.9780 - loss: 0.0000e+00 - val_accuracy: 0.9236 - val_loss: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 3/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 149ms/step - accuracy: 0.9760 - loss: 0.0000e+00 - val_accuracy: 0.9212 - val_loss: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 4/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 157ms/step - accuracy: 0.9799 - loss: 0.0000e+00 - val_accuracy: 0.9202 - val_loss: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 5/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 161ms/step - accuracy: 0.9806 - loss: 0.0000e+00 - val_accuracy: 0.9200 - val_loss: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 6/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 157ms/step - accuracy: 0.9827 - loss: 0.0000e+00 - val_accuracy: 0.9241 - val_loss: 0.0000e+00 - learning_rate: 0.0010\n",
            "Epoch 7/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 153ms/step - accuracy: 0.9886 - loss: 0.0000e+00 - val_accuracy: 0.9304 - val_loss: 0.0000e+00 - learning_rate: 2.0000e-04\n",
            "Epoch 8/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 156ms/step - accuracy: 0.9927 - loss: 0.0000e+00 - val_accuracy: 0.9324 - val_loss: 0.0000e+00 - learning_rate: 2.0000e-04\n",
            "Epoch 9/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 150ms/step - accuracy: 0.9931 - loss: 0.0000e+00 - val_accuracy: 0.9320 - val_loss: 0.0000e+00 - learning_rate: 2.0000e-04\n",
            "Epoch 10/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 154ms/step - accuracy: 0.9947 - loss: 0.0000e+00 - val_accuracy: 0.9350 - val_loss: 0.0000e+00 - learning_rate: 2.0000e-04\n",
            "Epoch 11/25\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 156ms/step - accuracy: 0.9954 - loss: 0.0000e+00 - val_accuracy: 0.9311 - val_loss: 0.0000e+00 - learning_rate: 2.0000e-04\n",
            "Epoch 11: early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model, Model\n",
        "from keras.layers import Input, Average\n",
        "\n",
        "# Load the pre-trained models\n",
        "model_1 = model\n",
        "model_2 = model_1\n",
        "\n",
        "# Create a new input layer that matches the input shape of the original models\n",
        "input_shape = (28, 28, 1)\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "# Get the outputs of the two models\n",
        "output_1 = model_1(inputs)\n",
        "output_2 = model_2(inputs)\n",
        "\n",
        "# Average the outputs of the two models\n",
        "averaged_output = Average()([output_1, output_2])\n",
        "\n",
        "# Create a new model with the same input layer and the averaged output\n",
        "ensemble_model = Model(inputs=inputs, outputs=averaged_output)\n",
        "\n",
        "# Compile the new ensemble model\n",
        "ensemble_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Assuming X_train, y_train, X_validate, y_validate are already defined and preprocessed\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
        "early_stopping_monitor = EarlyStopping(patience=10, monitor='val_accuracy', mode='min', verbose=1)\n",
        "\n",
        "history_ensemble = ensemble_model.fit(x_train, y_train_1,\n",
        "                                      batch_size=128,\n",
        "                                      epochs=25,\n",
        "                                      verbose=1,\n",
        "                                      validation_data=(x_test, y_test_1),\n",
        "                                      callbacks=[early_stopping_monitor, reduce_lr])\n",
        "\n",
        "ensemble_model.save('model/ensemble_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9261 - loss: 0.0000e+00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.0, 0.0, 0.9311000108718872, 0.9311000108718872]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_model.evaluate(x_test, y_test_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
